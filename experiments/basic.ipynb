{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(rc={'figure.figsize': (16, 9.)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys_data.spotlight_datasets import get_movielens_dataset, random_train_test_split\n",
    "from recsys_data.torch_utils import (cpu, gpu, minibatch, set_seed, shuffle, sample_items, \n",
    "                                     _predict_process_ids)\n",
    "from recsys_data.spotlight_evaluation import mrr_score, precision_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_movielens_dataset(variant='100K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledEmbedding(nn.Embedding):\n",
    "    \"\"\"\n",
    "    Embedding layer that initialises its values\n",
    "    to using a normal variable scaled by the inverse\n",
    "    of the embedding dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        self.weight.data.normal_(0, 1.0 / self.embedding_dim)\n",
    "        if self.padding_idx is not None:\n",
    "            self.weight.data[self.padding_idx].fill_(0)\n",
    "\n",
    "\n",
    "class ZeroEmbedding(nn.Embedding):\n",
    "    \"\"\"\n",
    "    Embedding layer that initialises its values\n",
    "    to using a normal variable scaled by the inverse\n",
    "    of the embedding dimension.\n",
    "\n",
    "    Used for biases.\n",
    "    \"\"\"\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        self.weight.data.zero_()\n",
    "        if self.padding_idx is not None:\n",
    "            self.weight.data[self.padding_idx].fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilinearNet(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32,\n",
    "                 user_embedding_layer=None, item_embedding_layer=None, sparse=False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        if user_embedding_layer is not None:\n",
    "            self.user_embeddings = user_embedding_layer\n",
    "        else:\n",
    "            self.user_embeddings = ScaledEmbedding(num_users, embedding_dim,\n",
    "                                                   sparse=sparse)\n",
    "\n",
    "        if item_embedding_layer is not None:\n",
    "            self.item_embeddings = item_embedding_layer\n",
    "        else:\n",
    "            self.item_embeddings = ScaledEmbedding(num_items, embedding_dim,\n",
    "                                                   sparse=sparse)\n",
    "\n",
    "        self.user_biases = ZeroEmbedding(num_users, 1, sparse=sparse)\n",
    "        self.item_biases = ZeroEmbedding(num_items, 1, sparse=sparse)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Compute the forward pass of the representation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        user_ids: tensor\n",
    "            Tensor of user indices.\n",
    "        item_ids: tensor\n",
    "            Tensor of item indices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        predictions: tensor\n",
    "            Tensor of predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_ids)\n",
    "        item_embedding = self.item_embeddings(item_ids)\n",
    "\n",
    "        user_embedding = user_embedding.squeeze()\n",
    "        item_embedding = item_embedding.squeeze()\n",
    "\n",
    "        user_bias = self.user_biases(user_ids).squeeze()\n",
    "        item_bias = self.item_biases(item_ids).squeeze()\n",
    "\n",
    "        dot = (user_embedding * item_embedding).sum(1)\n",
    "\n",
    "        return dot + user_bias + item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNet(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=8,\n",
    "                 user_embedding_layer=None, item_embedding_layer=None, sparse=False):\n",
    "\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.user_embeddings = ScaledEmbedding(num_users, embedding_dim, sparse=sparse)\n",
    "        self.item_embeddings = ScaledEmbedding(num_items, embedding_dim, sparse=sparse)\n",
    "\n",
    "        self._h1 = nn.Linear(2*embedding_dim, embedding_dim * 4)\n",
    "        self._h2 = nn.Linear(embedding_dim * 4 , embedding_dim * 2)\n",
    "        self._h3 = nn.Linear(embedding_dim * 2, 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Compute the forward pass of the representation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        user_ids: tensor\n",
    "            Tensor of user indices.\n",
    "        item_ids: tensor\n",
    "            Tensor of item indices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        predictions: tensor\n",
    "            Tensor of predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_ids)\n",
    "        item_embedding = self.item_embeddings(item_ids)\n",
    "        \n",
    "        embedding = torch.cat([user_embedding, item_embedding], dim=1)\n",
    "        hidden = torch.sigmoid(self._h1(embedding))\n",
    "        #if not self.training:\n",
    "        #    print(hidden)\n",
    "        hidden = torch.sigmoid(self._h2(hidden))\n",
    "        out = self._h3(hidden)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepBilinearNet(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32,\n",
    "                 user_embedding_layer=None, item_embedding_layer=None, sparse=False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        if user_embedding_layer is not None:\n",
    "            self.user_embeddings = user_embedding_layer\n",
    "        else:\n",
    "            self.user_embeddings = ScaledEmbedding(num_users, embedding_dim,\n",
    "                                                   sparse=sparse)\n",
    "\n",
    "        if item_embedding_layer is not None:\n",
    "            self.item_embeddings = item_embedding_layer\n",
    "        else:\n",
    "            self.item_embeddings = ScaledEmbedding(num_items, embedding_dim,\n",
    "                                                   sparse=sparse)\n",
    "\n",
    "        self._h1 = nn.Linear(embedding_dim, embedding_dim // 2)\n",
    "        self._h2 = nn.Linear(embedding_dim // 2 , embedding_dim // 4)\n",
    "        self._h3 = nn.Linear(embedding_dim // 4, 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Compute the forward pass of the representation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        user_ids: tensor\n",
    "            Tensor of user indices.\n",
    "        item_ids: tensor\n",
    "            Tensor of item indices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        predictions: tensor\n",
    "            Tensor of predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_ids)\n",
    "        item_embedding = self.item_embeddings(item_ids)\n",
    "\n",
    "        user_embedding = user_embedding.squeeze()\n",
    "        item_embedding = item_embedding.squeeze()\n",
    "\n",
    "        # Not needed since linar layer has biases\n",
    "        #user_bias = self.user_biases(user_ids).squeeze()\n",
    "        #item_bias = self.item_biases(item_ids).squeeze()\n",
    "\n",
    "        prod = user_embedding * item_embedding\n",
    "        hidden = torch.sigmoid(self._h1(prod))\n",
    "        hidden = torch.sigmoid(self._h2(hidden))\n",
    "        out = self._h3(hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMModel(object):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 num_users,\n",
    "                 num_items,\n",
    "                 net,\n",
    "                 embedding_dim=32,\n",
    "                 n_iter=10,\n",
    "                 batch_size=256,\n",
    "                 l2=0.0,\n",
    "                 learning_rate=1e-2,\n",
    "                 optimizer_func=None,\n",
    "                 use_cuda=False,\n",
    "                 sparse=False,\n",
    "                 random_state=None,\n",
    "                 num_negative_samples=5):\n",
    "\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._n_iter = n_iter\n",
    "        self._learning_rate = learning_rate\n",
    "        self._batch_size = batch_size\n",
    "        self._l2 = l2\n",
    "        self._use_cuda = use_cuda\n",
    "        self._sparse = sparse\n",
    "        self._random_state = random_state or np.random.RandomState()\n",
    "        self._num_negative_samples = num_negative_samples\n",
    "        self._net = net\n",
    "        self._num_items = num_items\n",
    "        self._num_users = num_users\n",
    "        self._optimizer = optim.Adam(\n",
    "            self._net.parameters(),\n",
    "            weight_decay=self._l2,\n",
    "            lr=self._learning_rate\n",
    "        )\n",
    "\n",
    "        set_seed(self._random_state.randint(-10**8, 10**8),\n",
    "                 cuda=self._use_cuda)\n",
    "\n",
    "    def _loss(self, positive_predictions, negative_predictions, mask=None):\n",
    "        loss = (1.0 - torch.sigmoid(positive_predictions -\n",
    "                                    negative_predictions))\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.float()\n",
    "            loss = loss * mask\n",
    "            return loss.sum() / mask.sum()\n",
    "\n",
    "        return loss.mean()\n",
    "\n",
    "    def fit(self, interactions, verbose=False):\n",
    "        \"\"\"\n",
    "        Fit the model.\n",
    "\n",
    "        When called repeatedly, model fitting will resume from\n",
    "        the point at which training stopped in the previous fit\n",
    "        call.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        interactions: :class:`spotlight.interactions.Interactions`\n",
    "            The input dataset.\n",
    "\n",
    "        verbose: bool\n",
    "            Output additional information about current epoch and loss.\n",
    "        \"\"\"\n",
    "\n",
    "        user_ids = interactions.user_ids.astype(np.int64)\n",
    "        item_ids = interactions.item_ids.astype(np.int64)\n",
    "\n",
    "        for epoch_num in range(self._n_iter):\n",
    "\n",
    "            users, items = shuffle(user_ids,\n",
    "                                   item_ids,\n",
    "                                   random_state=self._random_state)\n",
    "\n",
    "            user_ids_tensor = gpu(torch.from_numpy(users),\n",
    "                                  self._use_cuda)\n",
    "            item_ids_tensor = gpu(torch.from_numpy(items),\n",
    "                                  self._use_cuda)\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            a = gpu(torch.from_numpy(np.array([user_ids[10]])), self._use_cuda)\n",
    "            #print(self._net.user_embeddings(a))\n",
    "\n",
    "            for (minibatch_num,\n",
    "                 (batch_user,\n",
    "                  batch_item)) in enumerate(minibatch(user_ids_tensor,\n",
    "                                                      item_ids_tensor,\n",
    "                                                      batch_size=self._batch_size)):\n",
    "\n",
    "                user_var = Variable(batch_user)\n",
    "                item_var = Variable(batch_item)\n",
    "                positive_prediction = self._net(user_var, item_var)\n",
    "                negative_prediction = self._get_negative_prediction(user_var)\n",
    "                #negative_prediction = self._get_negative_prediction_items(item_var)\n",
    "\n",
    "                self._optimizer.zero_grad()\n",
    "\n",
    "                loss = self._loss(positive_prediction, negative_prediction)\n",
    "                # for scaled\n",
    "                #loss += 0.01 * torch.norm(self._net.scale - 1., 2)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "\n",
    "            epoch_loss /= minibatch_num + 1\n",
    "\n",
    "            if verbose:\n",
    "                print('Epoch {}: loss {}'.format(epoch_num, epoch_loss))\n",
    "\n",
    "            if np.isnan(epoch_loss) or epoch_loss == 0.0:\n",
    "                raise ValueError('Degenerate epoch loss: {}'\n",
    "                                 .format(epoch_loss))\n",
    "\n",
    "    def _get_negative_prediction(self, user_ids):\n",
    "\n",
    "        negative_items = sample_items(\n",
    "            self._num_items,\n",
    "            len(user_ids),\n",
    "            random_state= self._random_state) # np.random.RandomState(42))#\n",
    "        negative_var = Variable(\n",
    "            gpu(torch.from_numpy(negative_items), self._use_cuda)\n",
    "        )\n",
    "        negative_prediction = self._net(user_ids, negative_var)\n",
    "\n",
    "        return negative_prediction\n",
    "\n",
    "    def _get_negative_prediction_items(self, item_ids):\n",
    "\n",
    "        negative_users = sample_items(\n",
    "            self._num_users,\n",
    "            len(item_ids),\n",
    "            random_state= self._random_state) # np.random.RandomState(42))#\n",
    "        negative_var = Variable(\n",
    "            gpu(torch.from_numpy(negative_users), self._use_cuda)\n",
    "        )\n",
    "        negative_prediction = self._net(negative_var, item_ids)\n",
    "\n",
    "        return negative_prediction\n",
    "    \n",
    "    def _get_multiple_negative_predictions(self, user_ids, n=5):\n",
    "\n",
    "        batch_size = user_ids.size(0)\n",
    "\n",
    "        negative_prediction = self._get_negative_prediction(user_ids\n",
    "                                                            .resize(batch_size, 1)\n",
    "                                                            .expand(batch_size, n)\n",
    "                                                            .resize(batch_size * n))\n",
    "\n",
    "        return negative_prediction.view(n, len(user_ids))\n",
    "\n",
    "    def predict(self, user_ids, item_ids=None):\n",
    "        \"\"\"\n",
    "        Make predictions: given a user id, compute the recommendation\n",
    "        scores for items.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        user_ids: int or array\n",
    "           If int, will predict the recommendation scores for this\n",
    "           user for all items in item_ids. If an array, will predict\n",
    "           scores for all (user, item) pairs defined by user_ids and\n",
    "           item_ids.\n",
    "        item_ids: array, optional\n",
    "            Array containing the item ids for which prediction scores\n",
    "            are desired. If not supplied, predictions for all items\n",
    "            will be computed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        predictions: np.array\n",
    "            Predicted scores for all items in item_ids.\n",
    "        \"\"\"\n",
    "        self.training = False\n",
    "        self._net.train(False)\n",
    "\n",
    "        user_ids, item_ids = _predict_process_ids(user_ids, item_ids,\n",
    "                                                  self._num_items,\n",
    "                                                  self._use_cuda)\n",
    "\n",
    "        out = self._net(user_ids, item_ids)\n",
    "\n",
    "        return cpu(out.data).numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = random_train_test_split(data)\n",
    "\n",
    "num_users, num_items = data.num_users, data.num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gpu(BilinearNet(num_users, num_items, embedding_dim=32, sparse=False),\n",
    "          gpu=CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FMModel(net=net, num_users=num_users, num_items=num_items, n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.30181315155646293\n",
      "Epoch 1: loss 0.1711395392640711\n",
      "Epoch 2: loss 0.1547262336785039\n",
      "Epoch 3: loss 0.14716710788182938\n",
      "Epoch 4: loss 0.139536773863311\n",
      "Epoch 5: loss 0.13576723887516667\n",
      "Epoch 6: loss 0.12900713340828593\n",
      "Epoch 7: loss 0.12612181025952957\n",
      "Epoch 8: loss 0.12483221125869325\n",
      "Epoch 9: loss 0.12131513352877797\n",
      "Epoch 10: loss 0.1201091303992957\n",
      "Epoch 11: loss 0.118971790535191\n",
      "Epoch 12: loss 0.11656660529466482\n",
      "Epoch 13: loss 0.11565854953834043\n",
      "Epoch 14: loss 0.1142451648180858\n"
     ]
    }
   ],
   "source": [
    "loss = model.fit(train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5814422057264051"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec, recall = precision_recall_score(model, train)\n",
    "prec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5580063626723224"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec, recall = precision_recall_score(model, train)\n",
    "prec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12080679405520171"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec, recall = precision_recall_score(model, test)\n",
    "prec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09968152866242039"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec, recall = precision_recall_score(model, test)\n",
    "prec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0558032748722695, 0.04648800464464815)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_score(model, train).mean(), mrr_score(model, test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.052990519204356205, 0.03728451053949891)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_score(model, train).mean(), mrr_score(model, test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
